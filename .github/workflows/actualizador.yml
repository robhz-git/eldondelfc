name: Automatizacion ElDonDelFC Full
on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Instalar dependencias
        run: pip install requests beautifulsoup4

      - name: Actualizar Codigos y Noticias
        run: |
          python << END
          import requests
          from bs4 import BeautifulSoup
          import re
          import time

          headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

          # FUNCION PARA PETICIONES CON REINTENTOS
          def safe_get(url, is_xml=False):
              for i in range(3): # 3 intentos
                  try:
                      res = requests.get(url, headers=headers, timeout=20)
                      if res.status_code == 200:
                          return BeautifulSoup(res.content, "xml" if is_xml else "html.parser")
                  except:
                      time.sleep(2)
              return None

          # 1. EXTRACCIN DEL CDIGO
          soup_code = safe_get("https://www.fcmobileforum.com/fcmobile-redeem-codes")
          valid_code = "SIN CDIGOS NUEVOS"
          if soup_code:
              for tag in soup_code.find_all(['strong', 'td']):
                  text = tag.get_text().strip()
                  if text.isupper() and 5 < len(text) < 16 and " " not in text:
                      if not any(x in text for x in ["CODE", "REDEEM", "EXPIRED", "STATUS"]):
                          valid_code = text
                          break

          # 2. EXTRACCIN DE NOTICIAS (NUEVA LGICA ROBUSTA)
          def get_news(query):
              # Usamos la versi贸n de b煤squeda de Google News
              url = f"https://news.google.com/rss/search?q={query}&hl=es-419&gl=MX&ceid=MX:es-419"
              soup = safe_get(url, is_xml=True)
              if not soup:
                  return "<h4>Titulares en actualizaci贸n...</h4>"
              
              html = ""
              items = soup.find_all('item')
              for item in items[:4]:
                  title = item.title.text.rsplit(" - ", 1)[0] # Quita el nombre del medio al final
                  link = item.link.text
                  html += f'<div class="news-item"><h4>{title}</h4><a href=\"{link}\" target=\"_blank\">Leer noticia completa</a></div>'
              return html if html else "<h4>Buscando novedades...</h4>"

          mundial_html = get_news("Mundial 2026 FIFA ESPN")
          champions_html = get_news("UEFA Champions League ESPN")

          # 3. ACTUALIZAR INDEX.HTML
          with open('index.html', 'r', encoding='utf-8') as f:
              content = f.read()

          # Reemplazos con Regex
          content = re.sub(r'<div class="code-box" id="daily-code">.*?</div>', f'<div class="code-box" id="daily-code">{valid_code}</div>', content)
          content = re.sub(r'<div id="mundial-news" class="news-feed">.*?</div>', f'<div id="mundial-news" class="news-feed">{mundial_html}</div>', content, flags=re.DOTALL)
          content = re.sub(r'<div id="champions-news" class="news-feed" style="display:none;">.*?</div>', f'<div id="champions-news" class="news-feed" style="display:none;">{champions_html}</div>', content, flags=re.DOTALL)

          with open('index.html', 'w', encoding='utf-8') as f:
              f.write(content)
          END

      - name: Guardar cambios
        run: |
          git config --global user.name 'ElDonBot'
          git config --global user.email 'bot@eldondelfc.io'
          git add index.html
          git commit -m " Bot: Noticias y C贸digo (Fix Conexi贸n)" || exit 0
          git push
