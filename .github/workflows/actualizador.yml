name: Automatizacion ElDonDelFC Full
on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Instalar dependencias
        run: pip install requests beautifulsoup4 lxml

      - name: Actualizar Codigos y Noticias
        run: |
          python << END
          import requests
          from bs4 import BeautifulSoup
          import re

          headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

          # 1. EXTRACCIN DEL CDIGO FC MOBILE
          try:
              res = requests.get("https://www.fcmobileforum.com/fcmobile-redeem-codes", headers=headers, timeout=20)
              soup = BeautifulSoup(res.text, 'html.parser')
              potential_codes = soup.find_all(['strong', 'b', 'span'])
              
              valid_code = "SIN CDIGOS NUEVOS"
              for tag in potential_codes:
                  text = tag.get_text().strip()
                  # Regla: May煤sculas, sin espacios, entre 6 y 15 letras, sin palabras prohibidas
                  if text.isupper() and 5 < len(text) < 16 and " " not in text:
                      if not any(word in text for word in ["CODE", "REDEEM", "ACTIVE", "EXPIRED", "MOBILE", "LINK"]):
                          valid_code = text
                          break
          except:
              valid_code = "REVISA TIKTOK"

          # 2. EXTRACCIN DE NOTICIAS (M茅todo compatible con GitHub Actions)
          def get_news(query):
              # Usamos la URL de b煤squeda de Google News pero parseando como HTML normal para evitar errores de XML
              url = f"https://news.google.com/search?q={query}&hl=es-419&gl=MX&ceid=MX%3Aes-419"
              try:
                  res = requests.get(url, headers=headers, timeout=20)
                  soup = BeautifulSoup(res.text, 'html.parser')
                  # Google News usa etiquetas 'article' o h3 para los t铆tulos
                  articles = soup.find_all('article')
                  html_output = ""
                  count = 0
                  for art in articles:
                      if count >= 3: break
                      link_tag = art.find('a', href=True)
                      title_tag = art.find('h3') or art.find('h4')
                      if link_tag and title_tag:
                          title = title_tag.get_text()
                          # Convertir link relativo a absoluto
                          link = "https://news.google.com" + link_tag['href'][1:]
                          html_output += f'<div class="news-item"><h4>{title}</h4><a href=\"{link}\" target=\"_blank\">Leer noticia completa</a></div>'
                          count += 1
                  return html_output if html_output else "<h4>No hay noticias recientes</h4>"
              except Exception as e:
                  return f"<h4>Error al conectar: {str(e)}</h4>"

          mundial_html = get_news("Mundial 2026 FIFA")
          champions_html = get_news("Champions League")

          # 3. ACTUALIZAR INDEX.HTML
          with open('index.html', 'r', encoding='utf-8') as f:
              content = f.read()

          # Inyecci贸n de C贸digo
          content = re.sub(r'<div class="code-box" id="daily-code">.*?</div>', 
                           f'<div class="code-box" id="daily-code">{valid_code}</div>', content)
          
          # Inyecci贸n de Noticias Mundial
          content = re.sub(r'<div id="mundial-news" class="news-feed">.*?</div>', 
                           f'<div id="mundial-news" class="news-feed">{mundial_html}</div>', content, flags=re.DOTALL)
          
          # Inyecci贸n de Noticias Champions
          content = re.sub(r'<div id="champions-news" class="news-feed" style="display:none;">.*?</div>', 
                           f'<div id="champions-news" class="news-feed" style="display:none;">{champions_html}</div>', content, flags=re.DOTALL)

          with open('index.html', 'w', encoding='utf-8') as f:
              f.write(content)
          END

      - name: Guardar cambios
        run: |
          git config --global user.name 'ElDonBot'
          git config --global user.email 'bot@eldondelfc.io'
          git add index.html
          git commit -m " Bot: Sincronizaci贸n Total - Noticias y C贸digo" || exit 0
          git push
